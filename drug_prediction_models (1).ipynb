{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "drug-prediction-models.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7mP60ElmXh2"
      },
      "source": [
        "#Mount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2WOcOpIXGqu",
        "outputId": "d71de185-5e22-4281-d24d-a5f67605fe07"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PToQQONPmVUY"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSktQ6xKXP_A"
      },
      "source": [
        "# Imports\n",
        "#import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import scipy.cluster.hierarchy as sch\n",
        "plt.style.use('fivethirtyeight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbSbZ21Lnce4"
      },
      "source": [
        "#Data Dictionary:\n",
        "Column | Name\t| Data | Type | Description | Drug |\n",
        "Object\tType of drug (drugA, drugB, drugC, drugX, & drugY) (target)\n",
        "\n",
        "Age -\tInt\tAge of patient\n",
        "\n",
        "Sex -\tObject\tM (male) or F (female)\n",
        "\n",
        "BP - Object\tBlood pressure levels (low, normal, or high)\n",
        "\n",
        "Cholesterol\t- Object\tCholesterol levels (normal or high)\n",
        "\n",
        "Na_to_K\t- Float\tSodium to Potassium ratio in blood"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxjQTed_mapc"
      },
      "source": [
        "#Creating the Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "KDKnVV6wXWO0",
        "outputId": "91454dba-be62-4fc6-a44c-49cf4733c73d"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/PTDataScience/PandasForDataManipulation/drug200.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>BP</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>Na_to_K</th>\n",
              "      <th>Drug</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23</td>\n",
              "      <td>F</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>25.355</td>\n",
              "      <td>DrugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>47</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>13.093</td>\n",
              "      <td>drugC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>47</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>10.114</td>\n",
              "      <td>drugC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>28</td>\n",
              "      <td>F</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>7.798</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>61</td>\n",
              "      <td>F</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>18.043</td>\n",
              "      <td>DrugY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Age Sex      BP Cholesterol  Na_to_K   Drug\n",
              "0   23   F    HIGH        HIGH   25.355  DrugY\n",
              "1   47   M     LOW        HIGH   13.093  drugC\n",
              "2   47   M     LOW        HIGH   10.114  drugC\n",
              "3   28   F  NORMAL        HIGH    7.798  drugX\n",
              "4   61   F     LOW        HIGH   18.043  DrugY"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4kjrYCime9m"
      },
      "source": [
        "#Exploring the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "olshWUD9Xz5s",
        "outputId": "09e48ff1-158f-4ad3-9e55-99c33548764c"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>BP</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>Na_to_K</th>\n",
              "      <th>Drug</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23</td>\n",
              "      <td>F</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>25.355</td>\n",
              "      <td>DrugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>47</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>13.093</td>\n",
              "      <td>drugC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>47</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>10.114</td>\n",
              "      <td>drugC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>28</td>\n",
              "      <td>F</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>7.798</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>61</td>\n",
              "      <td>F</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>18.043</td>\n",
              "      <td>DrugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>56</td>\n",
              "      <td>F</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>11.567</td>\n",
              "      <td>drugC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>16</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>12.006</td>\n",
              "      <td>drugC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>52</td>\n",
              "      <td>M</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>9.894</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>23</td>\n",
              "      <td>M</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>14.020</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>40</td>\n",
              "      <td>F</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>11.349</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Age Sex      BP Cholesterol  Na_to_K   Drug\n",
              "0     23   F    HIGH        HIGH   25.355  DrugY\n",
              "1     47   M     LOW        HIGH   13.093  drugC\n",
              "2     47   M     LOW        HIGH   10.114  drugC\n",
              "3     28   F  NORMAL        HIGH    7.798  drugX\n",
              "4     61   F     LOW        HIGH   18.043  DrugY\n",
              "..   ...  ..     ...         ...      ...    ...\n",
              "195   56   F     LOW        HIGH   11.567  drugC\n",
              "196   16   M     LOW        HIGH   12.006  drugC\n",
              "197   52   M  NORMAL        HIGH    9.894  drugX\n",
              "198   23   M  NORMAL      NORMAL   14.020  drugX\n",
              "199   40   F     LOW      NORMAL   11.349  drugX\n",
              "\n",
              "[200 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr04WRyIpJfi"
      },
      "source": [
        "df.replace('DrugY', 'drugY', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "WNw9_g4epXbl",
        "outputId": "35add200-f3c0-4101-cc02-f2d04a6d747e"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>BP</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>Na_to_K</th>\n",
              "      <th>Drug</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23</td>\n",
              "      <td>F</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>25.355</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>47</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>13.093</td>\n",
              "      <td>drugC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>47</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>10.114</td>\n",
              "      <td>drugC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>28</td>\n",
              "      <td>F</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>7.798</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>61</td>\n",
              "      <td>F</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>18.043</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>56</td>\n",
              "      <td>F</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>11.567</td>\n",
              "      <td>drugC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>16</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>12.006</td>\n",
              "      <td>drugC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>52</td>\n",
              "      <td>M</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>9.894</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>23</td>\n",
              "      <td>M</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>14.020</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>40</td>\n",
              "      <td>F</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>11.349</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Age Sex      BP Cholesterol  Na_to_K   Drug\n",
              "0     23   F    HIGH        HIGH   25.355  drugY\n",
              "1     47   M     LOW        HIGH   13.093  drugC\n",
              "2     47   M     LOW        HIGH   10.114  drugC\n",
              "3     28   F  NORMAL        HIGH    7.798  drugX\n",
              "4     61   F     LOW        HIGH   18.043  drugY\n",
              "..   ...  ..     ...         ...      ...    ...\n",
              "195   56   F     LOW        HIGH   11.567  drugC\n",
              "196   16   M     LOW        HIGH   12.006  drugC\n",
              "197   52   M  NORMAL        HIGH    9.894  drugX\n",
              "198   23   M  NORMAL      NORMAL   14.020  drugX\n",
              "199   40   F     LOW      NORMAL   11.349  drugX\n",
              "\n",
              "[200 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a92SIrknqtGW",
        "outputId": "28e0b351-b6ce-406e-b71f-2ede3723eae5"
      },
      "source": [
        "df.tail(55)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>BP</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>Na_to_K</th>\n",
              "      <th>Drug</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>61</td>\n",
              "      <td>M</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>9.443</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>37</td>\n",
              "      <td>F</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>12.006</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>26</td>\n",
              "      <td>F</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>12.307</td>\n",
              "      <td>drugA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>61</td>\n",
              "      <td>F</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>7.340</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>22</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>8.151</td>\n",
              "      <td>drugC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>49</td>\n",
              "      <td>M</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>8.700</td>\n",
              "      <td>drugA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>68</td>\n",
              "      <td>M</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>11.009</td>\n",
              "      <td>drugB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>55</td>\n",
              "      <td>M</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>7.261</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>72</td>\n",
              "      <td>F</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>14.642</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>37</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>16.724</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>49</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>10.537</td>\n",
              "      <td>drugC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>31</td>\n",
              "      <td>M</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>11.227</td>\n",
              "      <td>drugA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>53</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>22.963</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>59</td>\n",
              "      <td>F</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>10.444</td>\n",
              "      <td>drugC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>34</td>\n",
              "      <td>F</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>12.923</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>30</td>\n",
              "      <td>F</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>10.443</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>57</td>\n",
              "      <td>F</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>9.945</td>\n",
              "      <td>drugB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>43</td>\n",
              "      <td>M</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>12.859</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>21</td>\n",
              "      <td>F</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>28.632</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>16</td>\n",
              "      <td>M</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>19.007</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>38</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>18.295</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>58</td>\n",
              "      <td>F</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>26.645</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>57</td>\n",
              "      <td>F</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>14.216</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>51</td>\n",
              "      <td>F</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>23.003</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>20</td>\n",
              "      <td>F</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>11.262</td>\n",
              "      <td>drugA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>28</td>\n",
              "      <td>F</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>12.879</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>45</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>10.017</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>39</td>\n",
              "      <td>F</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>17.225</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>41</td>\n",
              "      <td>F</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>18.739</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>42</td>\n",
              "      <td>M</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>12.766</td>\n",
              "      <td>drugA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>73</td>\n",
              "      <td>F</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>18.348</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>48</td>\n",
              "      <td>M</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>10.446</td>\n",
              "      <td>drugA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>25</td>\n",
              "      <td>M</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>19.011</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>39</td>\n",
              "      <td>M</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>15.969</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>67</td>\n",
              "      <td>F</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>15.891</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>22</td>\n",
              "      <td>F</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>22.818</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>59</td>\n",
              "      <td>F</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>13.884</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>20</td>\n",
              "      <td>F</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>11.686</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>36</td>\n",
              "      <td>F</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>15.490</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>18</td>\n",
              "      <td>F</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>37.188</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>57</td>\n",
              "      <td>F</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>25.893</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>70</td>\n",
              "      <td>M</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>9.849</td>\n",
              "      <td>drugB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>47</td>\n",
              "      <td>M</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>10.403</td>\n",
              "      <td>drugA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>65</td>\n",
              "      <td>M</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>34.997</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>64</td>\n",
              "      <td>M</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>20.932</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>58</td>\n",
              "      <td>M</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>18.991</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>23</td>\n",
              "      <td>M</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>8.011</td>\n",
              "      <td>drugA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>72</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>16.310</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>72</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>6.769</td>\n",
              "      <td>drugC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>46</td>\n",
              "      <td>F</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>34.686</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>56</td>\n",
              "      <td>F</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>11.567</td>\n",
              "      <td>drugC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>16</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>12.006</td>\n",
              "      <td>drugC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>52</td>\n",
              "      <td>M</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>9.894</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>23</td>\n",
              "      <td>M</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>14.020</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>40</td>\n",
              "      <td>F</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>11.349</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Age Sex      BP Cholesterol  Na_to_K   Drug\n",
              "145   61   M  NORMAL        HIGH    9.443  drugX\n",
              "146   37   F     LOW      NORMAL   12.006  drugX\n",
              "147   26   F    HIGH      NORMAL   12.307  drugA\n",
              "148   61   F     LOW      NORMAL    7.340  drugX\n",
              "149   22   M     LOW        HIGH    8.151  drugC\n",
              "150   49   M    HIGH      NORMAL    8.700  drugA\n",
              "151   68   M    HIGH        HIGH   11.009  drugB\n",
              "152   55   M  NORMAL      NORMAL    7.261  drugX\n",
              "153   72   F     LOW      NORMAL   14.642  drugX\n",
              "154   37   M     LOW      NORMAL   16.724  drugY\n",
              "155   49   M     LOW        HIGH   10.537  drugC\n",
              "156   31   M    HIGH      NORMAL   11.227  drugA\n",
              "157   53   M     LOW        HIGH   22.963  drugY\n",
              "158   59   F     LOW        HIGH   10.444  drugC\n",
              "159   34   F     LOW      NORMAL   12.923  drugX\n",
              "160   30   F  NORMAL        HIGH   10.443  drugX\n",
              "161   57   F    HIGH      NORMAL    9.945  drugB\n",
              "162   43   M  NORMAL      NORMAL   12.859  drugX\n",
              "163   21   F    HIGH      NORMAL   28.632  drugY\n",
              "164   16   M    HIGH      NORMAL   19.007  drugY\n",
              "165   38   M     LOW        HIGH   18.295  drugY\n",
              "166   58   F     LOW        HIGH   26.645  drugY\n",
              "167   57   F  NORMAL        HIGH   14.216  drugX\n",
              "168   51   F     LOW      NORMAL   23.003  drugY\n",
              "169   20   F    HIGH        HIGH   11.262  drugA\n",
              "170   28   F  NORMAL        HIGH   12.879  drugX\n",
              "171   45   M     LOW      NORMAL   10.017  drugX\n",
              "172   39   F  NORMAL      NORMAL   17.225  drugY\n",
              "173   41   F     LOW      NORMAL   18.739  drugY\n",
              "174   42   M    HIGH      NORMAL   12.766  drugA\n",
              "175   73   F    HIGH        HIGH   18.348  drugY\n",
              "176   48   M    HIGH      NORMAL   10.446  drugA\n",
              "177   25   M  NORMAL        HIGH   19.011  drugY\n",
              "178   39   M  NORMAL        HIGH   15.969  drugY\n",
              "179   67   F  NORMAL        HIGH   15.891  drugY\n",
              "180   22   F    HIGH      NORMAL   22.818  drugY\n",
              "181   59   F  NORMAL        HIGH   13.884  drugX\n",
              "182   20   F     LOW      NORMAL   11.686  drugX\n",
              "183   36   F    HIGH      NORMAL   15.490  drugY\n",
              "184   18   F    HIGH        HIGH   37.188  drugY\n",
              "185   57   F  NORMAL      NORMAL   25.893  drugY\n",
              "186   70   M    HIGH        HIGH    9.849  drugB\n",
              "187   47   M    HIGH        HIGH   10.403  drugA\n",
              "188   65   M    HIGH      NORMAL   34.997  drugY\n",
              "189   64   M    HIGH      NORMAL   20.932  drugY\n",
              "190   58   M    HIGH        HIGH   18.991  drugY\n",
              "191   23   M    HIGH        HIGH    8.011  drugA\n",
              "192   72   M     LOW        HIGH   16.310  drugY\n",
              "193   72   M     LOW        HIGH    6.769  drugC\n",
              "194   46   F    HIGH        HIGH   34.686  drugY\n",
              "195   56   F     LOW        HIGH   11.567  drugC\n",
              "196   16   M     LOW        HIGH   12.006  drugC\n",
              "197   52   M  NORMAL        HIGH    9.894  drugX\n",
              "198   23   M  NORMAL      NORMAL   14.020  drugX\n",
              "199   40   F     LOW      NORMAL   11.349  drugX"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mJlaHHD_q4U7",
        "outputId": "41af00e1-f8b9-45f7-a5ee-0d315b4839b7"
      },
      "source": [
        "df.head(55)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>BP</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>Na_to_K</th>\n",
              "      <th>Drug</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23</td>\n",
              "      <td>F</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>25.355</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>47</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>13.093</td>\n",
              "      <td>drugC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>47</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>10.114</td>\n",
              "      <td>drugC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>28</td>\n",
              "      <td>F</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>7.798</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>61</td>\n",
              "      <td>F</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>18.043</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>22</td>\n",
              "      <td>F</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>8.607</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>49</td>\n",
              "      <td>F</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>16.275</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>41</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>11.037</td>\n",
              "      <td>drugC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>60</td>\n",
              "      <td>M</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>15.171</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>43</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>19.368</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>47</td>\n",
              "      <td>F</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>11.767</td>\n",
              "      <td>drugC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>34</td>\n",
              "      <td>F</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>19.199</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>43</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>15.376</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>74</td>\n",
              "      <td>F</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>20.942</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>50</td>\n",
              "      <td>F</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>12.703</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>F</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>15.516</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>69</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>11.455</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>43</td>\n",
              "      <td>M</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>13.972</td>\n",
              "      <td>drugA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>23</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>7.298</td>\n",
              "      <td>drugC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>32</td>\n",
              "      <td>F</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>25.974</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>57</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>19.128</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>63</td>\n",
              "      <td>M</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>25.917</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>47</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>30.568</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>48</td>\n",
              "      <td>F</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>15.036</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>33</td>\n",
              "      <td>F</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>33.486</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>28</td>\n",
              "      <td>F</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>18.809</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>31</td>\n",
              "      <td>M</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>30.366</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>49</td>\n",
              "      <td>F</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>9.381</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>39</td>\n",
              "      <td>F</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>22.697</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>45</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>17.951</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>18</td>\n",
              "      <td>F</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>8.750</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>74</td>\n",
              "      <td>M</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>9.567</td>\n",
              "      <td>drugB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>49</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>11.014</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>65</td>\n",
              "      <td>F</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>31.876</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>53</td>\n",
              "      <td>M</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>14.133</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>46</td>\n",
              "      <td>M</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>7.285</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>32</td>\n",
              "      <td>M</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>9.445</td>\n",
              "      <td>drugA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>39</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>13.938</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>39</td>\n",
              "      <td>F</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>9.709</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>15</td>\n",
              "      <td>M</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>9.084</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>73</td>\n",
              "      <td>F</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>19.221</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>58</td>\n",
              "      <td>F</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>14.239</td>\n",
              "      <td>drugB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>50</td>\n",
              "      <td>M</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>15.790</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>23</td>\n",
              "      <td>M</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>12.260</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>50</td>\n",
              "      <td>F</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>12.295</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>66</td>\n",
              "      <td>F</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>8.107</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>37</td>\n",
              "      <td>F</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>13.091</td>\n",
              "      <td>drugA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>68</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>10.291</td>\n",
              "      <td>drugC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>23</td>\n",
              "      <td>M</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>31.686</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>28</td>\n",
              "      <td>F</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>19.796</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>58</td>\n",
              "      <td>F</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>19.416</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>67</td>\n",
              "      <td>M</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>10.898</td>\n",
              "      <td>drugX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>62</td>\n",
              "      <td>M</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>27.183</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>24</td>\n",
              "      <td>F</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>18.457</td>\n",
              "      <td>drugY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>68</td>\n",
              "      <td>F</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>NORMAL</td>\n",
              "      <td>10.189</td>\n",
              "      <td>drugB</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Age Sex      BP Cholesterol  Na_to_K   Drug\n",
              "0    23   F    HIGH        HIGH   25.355  drugY\n",
              "1    47   M     LOW        HIGH   13.093  drugC\n",
              "2    47   M     LOW        HIGH   10.114  drugC\n",
              "3    28   F  NORMAL        HIGH    7.798  drugX\n",
              "4    61   F     LOW        HIGH   18.043  drugY\n",
              "5    22   F  NORMAL        HIGH    8.607  drugX\n",
              "6    49   F  NORMAL        HIGH   16.275  drugY\n",
              "7    41   M     LOW        HIGH   11.037  drugC\n",
              "8    60   M  NORMAL        HIGH   15.171  drugY\n",
              "9    43   M     LOW      NORMAL   19.368  drugY\n",
              "10   47   F     LOW        HIGH   11.767  drugC\n",
              "11   34   F    HIGH      NORMAL   19.199  drugY\n",
              "12   43   M     LOW        HIGH   15.376  drugY\n",
              "13   74   F     LOW        HIGH   20.942  drugY\n",
              "14   50   F  NORMAL        HIGH   12.703  drugX\n",
              "15   16   F    HIGH      NORMAL   15.516  drugY\n",
              "16   69   M     LOW      NORMAL   11.455  drugX\n",
              "17   43   M    HIGH        HIGH   13.972  drugA\n",
              "18   23   M     LOW        HIGH    7.298  drugC\n",
              "19   32   F    HIGH      NORMAL   25.974  drugY\n",
              "20   57   M     LOW      NORMAL   19.128  drugY\n",
              "21   63   M  NORMAL        HIGH   25.917  drugY\n",
              "22   47   M     LOW      NORMAL   30.568  drugY\n",
              "23   48   F     LOW        HIGH   15.036  drugY\n",
              "24   33   F     LOW        HIGH   33.486  drugY\n",
              "25   28   F    HIGH      NORMAL   18.809  drugY\n",
              "26   31   M    HIGH        HIGH   30.366  drugY\n",
              "27   49   F  NORMAL      NORMAL    9.381  drugX\n",
              "28   39   F     LOW      NORMAL   22.697  drugY\n",
              "29   45   M     LOW        HIGH   17.951  drugY\n",
              "30   18   F  NORMAL      NORMAL    8.750  drugX\n",
              "31   74   M    HIGH        HIGH    9.567  drugB\n",
              "32   49   M     LOW      NORMAL   11.014  drugX\n",
              "33   65   F    HIGH      NORMAL   31.876  drugY\n",
              "34   53   M  NORMAL        HIGH   14.133  drugX\n",
              "35   46   M  NORMAL      NORMAL    7.285  drugX\n",
              "36   32   M    HIGH      NORMAL    9.445  drugA\n",
              "37   39   M     LOW      NORMAL   13.938  drugX\n",
              "38   39   F  NORMAL      NORMAL    9.709  drugX\n",
              "39   15   M  NORMAL        HIGH    9.084  drugX\n",
              "40   73   F  NORMAL        HIGH   19.221  drugY\n",
              "41   58   F    HIGH      NORMAL   14.239  drugB\n",
              "42   50   M  NORMAL      NORMAL   15.790  drugY\n",
              "43   23   M  NORMAL        HIGH   12.260  drugX\n",
              "44   50   F  NORMAL      NORMAL   12.295  drugX\n",
              "45   66   F  NORMAL      NORMAL    8.107  drugX\n",
              "46   37   F    HIGH        HIGH   13.091  drugA\n",
              "47   68   M     LOW        HIGH   10.291  drugC\n",
              "48   23   M  NORMAL        HIGH   31.686  drugY\n",
              "49   28   F     LOW        HIGH   19.796  drugY\n",
              "50   58   F    HIGH        HIGH   19.416  drugY\n",
              "51   67   M  NORMAL      NORMAL   10.898  drugX\n",
              "52   62   M     LOW      NORMAL   27.183  drugY\n",
              "53   24   F    HIGH      NORMAL   18.457  drugY\n",
              "54   68   F    HIGH      NORMAL   10.189  drugB"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUZukXc0safA",
        "outputId": "2c53f0f7-3283-48b5-82c9-87b6ee94d54d"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age              int64\n",
              "Sex             object\n",
              "BP              object\n",
              "Cholesterol     object\n",
              "Na_to_K        float64\n",
              "Drug            object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5sAlNHSp9ul",
        "outputId": "ad5c7316-583e-4a51-e6c0-4710007fc01c"
      },
      "source": [
        "df['Drug'].nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxwjfasad0-V",
        "outputId": "bc4349a1-4660-4130-f399-b4c4c494f1b7"
      },
      "source": [
        "df.isnull().value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age    Sex    BP     Cholesterol  Na_to_K  Drug \n",
              "False  False  False  False        False    False    200\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBvYcF1CeQTR",
        "outputId": "6acb7506-5f42-4df3-9a6b-5274f7795b0a"
      },
      "source": [
        "#This is to double check to make sure there are no Null values left\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age            0\n",
              "Sex            0\n",
              "BP             0\n",
              "Cholesterol    0\n",
              "Na_to_K        0\n",
              "Drug           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6ZiceXMYi81",
        "outputId": "28153d6f-cbcd-4e74-8036-c4fbe10cb1ad"
      },
      "source": [
        "df.duplicated() == True"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      False\n",
              "1      False\n",
              "2      False\n",
              "3      False\n",
              "4      False\n",
              "       ...  \n",
              "195    False\n",
              "196    False\n",
              "197    False\n",
              "198    False\n",
              "199    False\n",
              "Length: 200, dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xczMgRvqoQQY",
        "outputId": "fc6bbc8a-08fa-419b-dc5c-42d5296aae60"
      },
      "source": [
        "df.nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age             57\n",
              "Sex              2\n",
              "BP               3\n",
              "Cholesterol      2\n",
              "Na_to_K        198\n",
              "Drug             5\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1ebossZajCF"
      },
      "source": [
        "# Label Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp9VzrkgB8rU"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFXdvX0nB-BI"
      },
      "source": [
        "#categorical data\n",
        "categorical_cols = ['Sex', 'BP', 'Cholesterol','Drug'] \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# instantiate labelencoder object\n",
        "le = LabelEncoder()\n",
        "# apply le on categorical feature columns\n",
        "df[categorical_cols] = df[categorical_cols].apply(lambda col: le.fit_transform(col))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "pTXqRweLCm8z",
        "outputId": "9332505a-176c-4e01-cee1-f3fbd3f16859"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Sex</th>\n",
              "      <th>BP</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>Na_to_K</th>\n",
              "      <th>Drug</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.355</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>13.093</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10.114</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>7.798</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>18.043</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11.567</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>12.006</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>9.894</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>14.020</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11.349</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Age  Sex  BP  Cholesterol  Na_to_K  Drug\n",
              "0     23    0   0            0   25.355     4\n",
              "1     47    1   1            0   13.093     2\n",
              "2     47    1   1            0   10.114     2\n",
              "3     28    0   2            0    7.798     3\n",
              "4     61    0   1            0   18.043     4\n",
              "..   ...  ...  ..          ...      ...   ...\n",
              "195   56    0   1            0   11.567     2\n",
              "196   16    1   1            0   12.006     2\n",
              "197   52    1   2            0    9.894     3\n",
              "198   23    1   2            1   14.020     3\n",
              "199   40    0   1            1   11.349     3\n",
              "\n",
              "[200 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjm6XXcoYoy5",
        "outputId": "bfdeb3cb-038d-4810-e97d-decb995c637d"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K', 'Drug'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTfU6gcAC1RA"
      },
      "source": [
        "X = df.loc[:, ['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K']]\n",
        "y = df['Drug']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZR61kt2Df43",
        "outputId": "7db6ff4a-94d5-448d-e4ce-bbdfe6656744"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNPLOIrbDh_-",
        "outputId": "8a5d326c-44a5-4f9f-fe47-21517cca15bb"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZyiddiREGMW"
      },
      "source": [
        "#Splitting into Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW1wP0U_EHqr"
      },
      "source": [
        "# Importing the Keras libraries and packages\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pN5bE5MZEK_Y"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def cross_val(model):\n",
        "    pred = cross_val_score(model, X, y, cv=10)\n",
        "    return pred.mean()\n",
        "\n",
        "def print_evaluate(true, predicted):  \n",
        "    mae = metrics.mean_absolute_error(true, predicted)\n",
        "    mse = metrics.mean_squared_error(true, predicted)\n",
        "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
        "    r2_square = metrics.r2_score(true, predicted)\n",
        "    print('MAE:', mae)\n",
        "    print('MSE:', mse)\n",
        "    print('RMSE:', rmse)\n",
        "    print('R2 Square', r2_square)\n",
        "    \n",
        "def evaluate(true, predicted):\n",
        "    mae = metrics.mean_absolute_error(true, predicted)\n",
        "    mse = metrics.mean_squared_error(true, predicted)\n",
        "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
        "    r2_square = metrics.r2_score(true, predicted)\n",
        "    return mae, mse, rmse, r2_square\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CfR-E5fcYo6"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "# Fit on training set only.\n",
        "scaler.fit(X_train)\n",
        "# Apply transform to both the training set and the test set.\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDD5e6G3E8o4"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('std_scalar', StandardScaler())\n",
        "])\n",
        "\n",
        "X_train = pipeline.fit_transform(X_train)\n",
        "X_test = pipeline.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN8XA1sjaH6f"
      },
      "source": [
        "# Linear Regress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeFwX1ozE-m0",
        "outputId": "1ad6f7ed-40aa-4042-bd50-bd054a1a34e3"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lin_reg = LinearRegression(normalize=True, fit_intercept=True, )\n",
        "lin_reg.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibPQumyYFC6O",
        "outputId": "502fedc1-2f6b-4ef7-d25e-260482464c47"
      },
      "source": [
        "# print the intercept\n",
        "print(lin_reg.intercept_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "7_8_tHriFGZ-",
        "outputId": "b0bccce0-7dd6-4e1d-fad3-57debb26efa5"
      },
      "source": [
        "coeff_df = pd.DataFrame(lin_reg.coef_, X.columns, columns=['Coefficient'])\n",
        "coeff_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Coefficient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>0.052757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sex</th>\n",
              "      <td>-0.049667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BP</th>\n",
              "      <td>0.658549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cholesterol</th>\n",
              "      <td>0.135133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Na_to_K</th>\n",
              "      <td>0.908318</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Coefficient\n",
              "Age             0.052757\n",
              "Sex            -0.049667\n",
              "BP              0.658549\n",
              "Cholesterol     0.135133\n",
              "Na_to_K         0.908318"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i72MeFMsFOyP"
      },
      "source": [
        "pred = lin_reg.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDBDxeJbaUuk",
        "outputId": "4d1572a6-59c0-47f6-a10e-19c52ecf6339"
      },
      "source": [
        "lin_reg.score(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5751422282613415"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luVOxSu-acBT",
        "outputId": "2cb85905-c4ca-4e48-da3b-6bacc2116ec9"
      },
      "source": [
        "lin_reg.score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5672591194358907"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "7aCd-mLIFRWW",
        "outputId": "7c83e9f2-9755-435f-c196-b746ef1f79e9"
      },
      "source": [
        "plt.scatter(y_test, pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f3b0dc77d10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "1Qt89XZdFUuX",
        "outputId": "e0999dea-2bcf-4c1f-8552-da34ee9042f9"
      },
      "source": [
        "sns.distplot((y_test - pred), bins=58);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMqfxNkYFhXk",
        "outputId": "2411ad52-0130-4014-aaa9-15054eea2a55"
      },
      "source": [
        "test_pred = lin_reg.predict(X_test)\n",
        "train_pred = lin_reg.predict(X_train)\n",
        "\n",
        "print('Test set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_test, test_pred)\n",
        "print('====================================')\n",
        "print('Train set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_train, train_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set evaluation:\n",
            "_____________________________________\n",
            "MAE: 0.7476745840192895\n",
            "MSE: 0.8773821353437314\n",
            "RMSE: 0.9366867861477131\n",
            "R2 Square 0.5672591194358907\n",
            "====================================\n",
            "Train set evaluation:\n",
            "_____________________________________\n",
            "MAE: 0.7019831738278622\n",
            "MSE: 0.7729756084570217\n",
            "RMSE: 0.8791903141283016\n",
            "R2 Square 0.5751422282613415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "Aqu8l8hZFojU",
        "outputId": "1dffb2de-f8c4-4a0f-b138-e86651f65c88"
      },
      "source": [
        "results_df = pd.DataFrame(data=[[\"Linear Regression\", *evaluate(y_test, test_pred) , cross_val(LinearRegression())]], \n",
        "                          columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
        "results_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2 Square</th>\n",
              "      <th>Cross Validation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>0.747675</td>\n",
              "      <td>0.877382</td>\n",
              "      <td>0.936687</td>\n",
              "      <td>0.567259</td>\n",
              "      <td>0.509614</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Model       MAE       MSE      RMSE  R2 Square  Cross Validation\n",
              "0  Linear Regression  0.747675  0.877382  0.936687   0.567259          0.509614"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_uUm5VyF1zZ"
      },
      "source": [
        "# Next ro"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7FHlEe9F37U",
        "outputId": "0d9404bd-c56e-44bb-c3ae-5560925a75cb"
      },
      "source": [
        "from sklearn.linear_model import RANSACRegressor\n",
        "\n",
        "model = RANSACRegressor(base_estimator=LinearRegression(), max_trials=100)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "test_pred = model.predict(X_test)\n",
        "train_pred = model.predict(X_train)\n",
        "\n",
        "print('Test set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_test, test_pred)\n",
        "print('====================================')\n",
        "print('Train set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_train, train_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set evaluation:\n",
            "_____________________________________\n",
            "MAE: 1.0479792946452755\n",
            "MSE: 2.7073166609293438\n",
            "RMSE: 1.6453925552673878\n",
            "R2 Square -0.33529798319573056\n",
            "====================================\n",
            "Train set evaluation:\n",
            "_____________________________________\n",
            "MAE: 0.8867025577871332\n",
            "MSE: 2.0821537082804884\n",
            "RMSE: 1.4429669810083974\n",
            "R2 Square -0.1444335050665686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "WjPFmgsdF5ld",
        "outputId": "44f49541-b99c-41d7-a88a-eb66a94e3a86"
      },
      "source": [
        "results_df_2 = pd.DataFrame(data=[[\"Robust Regression\", *evaluate(y_test, test_pred) , cross_val(RANSACRegressor())]], \n",
        "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
        "results_df = results_df.append(results_df_2, ignore_index=True)\n",
        "results_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2 Square</th>\n",
              "      <th>Cross Validation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>0.747675</td>\n",
              "      <td>0.877382</td>\n",
              "      <td>0.936687</td>\n",
              "      <td>0.567259</td>\n",
              "      <td>0.509614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Robust Regression</td>\n",
              "      <td>1.047979</td>\n",
              "      <td>2.707317</td>\n",
              "      <td>1.645393</td>\n",
              "      <td>-0.335298</td>\n",
              "      <td>-0.163998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Model       MAE       MSE      RMSE  R2 Square  Cross Validation\n",
              "0  Linear Regression  0.747675  0.877382  0.936687   0.567259          0.509614\n",
              "1  Robust Regression  1.047979  2.707317  1.645393  -0.335298         -0.163998"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMVC15N_F-5H"
      },
      "source": [
        "# Ridge regress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEpm-oTwF-Tc",
        "outputId": "6cc0830b-bec1-418e-971d-a6483f5bc8c4"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "model = Ridge(alpha=100, solver='cholesky', tol=0.0001, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "test_pred = model.predict(X_test)\n",
        "train_pred = model.predict(X_train)\n",
        "\n",
        "print('Test set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_test, test_pred)\n",
        "print('====================================')\n",
        "print('Train set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_train, train_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set evaluation:\n",
            "_____________________________________\n",
            "MAE: 0.8106670980640274\n",
            "MSE: 1.1568765615704844\n",
            "RMSE: 1.075581964134061\n",
            "R2 Square 0.4294073679060496\n",
            "====================================\n",
            "Train set evaluation:\n",
            "_____________________________________\n",
            "MAE: 0.7513247504419468\n",
            "MSE: 0.968417120027674\n",
            "RMSE: 0.9840818665272082\n",
            "R2 Square 0.46771989280512594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "yyIblXeiGGw2",
        "outputId": "c5739479-2a48-4893-cbcd-788d85a579fe"
      },
      "source": [
        "results_df_2 = pd.DataFrame(data=[[\"Ridge Regression\", *evaluate(y_test, test_pred) , cross_val(Ridge())]], \n",
        "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
        "results_df = results_df.append(results_df_2, ignore_index=True)\n",
        "results_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2 Square</th>\n",
              "      <th>Cross Validation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>0.747675</td>\n",
              "      <td>0.877382</td>\n",
              "      <td>0.936687</td>\n",
              "      <td>0.567259</td>\n",
              "      <td>0.509614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Robust Regression</td>\n",
              "      <td>1.047979</td>\n",
              "      <td>2.707317</td>\n",
              "      <td>1.645393</td>\n",
              "      <td>-0.335298</td>\n",
              "      <td>-0.163998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ridge Regression</td>\n",
              "      <td>0.810667</td>\n",
              "      <td>1.156877</td>\n",
              "      <td>1.075582</td>\n",
              "      <td>0.429407</td>\n",
              "      <td>0.510120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Model       MAE       MSE      RMSE  R2 Square  Cross Validation\n",
              "0  Linear Regression  0.747675  0.877382  0.936687   0.567259          0.509614\n",
              "1  Robust Regression  1.047979  2.707317  1.645393  -0.335298         -0.163998\n",
              "2   Ridge Regression  0.810667  1.156877  1.075582   0.429407          0.510120"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEn5GySQGLWC"
      },
      "source": [
        "# lasso regress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DIZEHn5GNkX",
        "outputId": "d292b928-7fa5-48a7-f337-eec8cf37edc4"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "model = Lasso(alpha=0.1, \n",
        "              precompute=True, \n",
        "#               warm_start=True, \n",
        "              positive=True, \n",
        "              selection='random',\n",
        "              random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "test_pred = model.predict(X_test)\n",
        "train_pred = model.predict(X_train)\n",
        "\n",
        "print('Test set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_test, test_pred)\n",
        "print('====================================')\n",
        "print('Train set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_train, train_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set evaluation:\n",
            "_____________________________________\n",
            "MAE: 0.779502164593857\n",
            "MSE: 0.9520906559647054\n",
            "RMSE: 0.9757513289587185\n",
            "R2 Square 0.5304115137042142\n",
            "====================================\n",
            "Train set evaluation:\n",
            "_____________________________________\n",
            "MAE: 0.7201727834008138\n",
            "MSE: 0.8179088689982056\n",
            "RMSE: 0.9043831428096201\n",
            "R2 Square 0.5504451424262697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "6FBfg0EeGJbD",
        "outputId": "1f936a83-9cf3-4066-be6e-dd8229616571"
      },
      "source": [
        "results_df_2 = pd.DataFrame(data=[[\"Lasso Regression\", *evaluate(y_test, test_pred) , cross_val(Lasso())]], \n",
        "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
        "results_df = results_df.append(results_df_2, ignore_index=True)\n",
        "results_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2 Square</th>\n",
              "      <th>Cross Validation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>0.747675</td>\n",
              "      <td>0.877382</td>\n",
              "      <td>0.936687</td>\n",
              "      <td>0.567259</td>\n",
              "      <td>0.509614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Robust Regression</td>\n",
              "      <td>1.047979</td>\n",
              "      <td>2.707317</td>\n",
              "      <td>1.645393</td>\n",
              "      <td>-0.335298</td>\n",
              "      <td>-0.163998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ridge Regression</td>\n",
              "      <td>0.810667</td>\n",
              "      <td>1.156877</td>\n",
              "      <td>1.075582</td>\n",
              "      <td>0.429407</td>\n",
              "      <td>0.510120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lasso Regression</td>\n",
              "      <td>0.779502</td>\n",
              "      <td>0.952091</td>\n",
              "      <td>0.975751</td>\n",
              "      <td>0.530412</td>\n",
              "      <td>0.285220</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Model       MAE       MSE      RMSE  R2 Square  Cross Validation\n",
              "0  Linear Regression  0.747675  0.877382  0.936687   0.567259          0.509614\n",
              "1  Robust Regression  1.047979  2.707317  1.645393  -0.335298         -0.163998\n",
              "2   Ridge Regression  0.810667  1.156877  1.075582   0.429407          0.510120\n",
              "3   Lasso Regression  0.779502  0.952091  0.975751   0.530412          0.285220"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MNG-5uXGYaj"
      },
      "source": [
        "# Elastic net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcRwhF-zGWkA",
        "outputId": "df4aeea1-d8eb-4346-f664-f27aec888e31"
      },
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "model = ElasticNet(alpha=0.1, l1_ratio=0.9, selection='random', random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "test_pred = model.predict(X_test)\n",
        "train_pred = model.predict(X_train)\n",
        "\n",
        "print('Test set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_test, test_pred)\n",
        "print('====================================')\n",
        "print('Train set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_train, train_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set evaluation:\n",
            "_____________________________________\n",
            "MAE: 0.7750614794420263\n",
            "MSE: 0.942851993458777\n",
            "RMSE: 0.9710056608788524\n",
            "R2 Square 0.5349681906491852\n",
            "====================================\n",
            "Train set evaluation:\n",
            "_____________________________________\n",
            "MAE: 0.718032093667339\n",
            "MSE: 0.813613325937899\n",
            "RMSE: 0.9020051695738218\n",
            "R2 Square 0.5528061417036625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "IkKoryQrGm9P",
        "outputId": "5d1b86c8-17e9-4057-e7ac-325f5b22579e"
      },
      "source": [
        "results_df_2 = pd.DataFrame(data=[[\"Elastic Net Regression\", *evaluate(y_test, test_pred) , cross_val(ElasticNet())]], \n",
        "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
        "results_df = results_df.append(results_df_2, ignore_index=True)\n",
        "results_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2 Square</th>\n",
              "      <th>Cross Validation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>0.747675</td>\n",
              "      <td>0.877382</td>\n",
              "      <td>0.936687</td>\n",
              "      <td>0.567259</td>\n",
              "      <td>0.509614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Robust Regression</td>\n",
              "      <td>1.047979</td>\n",
              "      <td>2.707317</td>\n",
              "      <td>1.645393</td>\n",
              "      <td>-0.335298</td>\n",
              "      <td>-0.163998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ridge Regression</td>\n",
              "      <td>0.810667</td>\n",
              "      <td>1.156877</td>\n",
              "      <td>1.075582</td>\n",
              "      <td>0.429407</td>\n",
              "      <td>0.510120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lasso Regression</td>\n",
              "      <td>0.779502</td>\n",
              "      <td>0.952091</td>\n",
              "      <td>0.975751</td>\n",
              "      <td>0.530412</td>\n",
              "      <td>0.285220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Elastic Net Regression</td>\n",
              "      <td>0.775061</td>\n",
              "      <td>0.942852</td>\n",
              "      <td>0.971006</td>\n",
              "      <td>0.534968</td>\n",
              "      <td>0.293492</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Model       MAE  ...  R2 Square  Cross Validation\n",
              "0       Linear Regression  0.747675  ...   0.567259          0.509614\n",
              "1       Robust Regression  1.047979  ...  -0.335298         -0.163998\n",
              "2        Ridge Regression  0.810667  ...   0.429407          0.510120\n",
              "3        Lasso Regression  0.779502  ...   0.530412          0.285220\n",
              "4  Elastic Net Regression  0.775061  ...   0.534968          0.293492\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOzckT-mG8G4"
      },
      "source": [
        "# Tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53s6gZa8G96n",
        "outputId": "0f4b0f1f-c1b3-4555-9b88-250658c931a2"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer=Adam(0.00001), loss='mse')\n",
        "\n",
        "r = model.fit(X_train, y_train,\n",
        "              validation_data=(X_test,y_test),\n",
        "              batch_size=1,\n",
        "              epochs=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 9.9878 - val_loss: 8.4329\n",
            "Epoch 2/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.9706 - val_loss: 8.0003\n",
            "Epoch 3/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.7771 - val_loss: 7.5178\n",
            "Epoch 4/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.6736 - val_loss: 6.9586\n",
            "Epoch 5/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.0486 - val_loss: 6.3480\n",
            "Epoch 6/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.3240 - val_loss: 5.7039\n",
            "Epoch 7/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.6796 - val_loss: 5.0768\n",
            "Epoch 8/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.7037 - val_loss: 4.5231\n",
            "Epoch 9/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 5.2509 - val_loss: 4.0905\n",
            "Epoch 10/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.1357 - val_loss: 3.7927\n",
            "Epoch 11/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.7988 - val_loss: 3.5890\n",
            "Epoch 12/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.9422 - val_loss: 3.4582\n",
            "Epoch 13/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.5469 - val_loss: 3.3704\n",
            "Epoch 14/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.4525 - val_loss: 3.2970\n",
            "Epoch 15/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.9698 - val_loss: 3.2376\n",
            "Epoch 16/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.2075 - val_loss: 3.1774\n",
            "Epoch 17/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.2964 - val_loss: 3.1197\n",
            "Epoch 18/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.1572 - val_loss: 3.0641\n",
            "Epoch 19/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.0395 - val_loss: 3.0085\n",
            "Epoch 20/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.7278 - val_loss: 2.9563\n",
            "Epoch 21/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.1489 - val_loss: 2.9050\n",
            "Epoch 22/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.6144 - val_loss: 2.8578\n",
            "Epoch 23/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.9403 - val_loss: 2.8089\n",
            "Epoch 24/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.3208 - val_loss: 2.7630\n",
            "Epoch 25/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.4115 - val_loss: 2.7233\n",
            "Epoch 26/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2981 - val_loss: 2.6761\n",
            "Epoch 27/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2484 - val_loss: 2.6286\n",
            "Epoch 28/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2959 - val_loss: 2.5897\n",
            "Epoch 29/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.3840 - val_loss: 2.5463\n",
            "Epoch 30/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.3858 - val_loss: 2.5084\n",
            "Epoch 31/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.9349 - val_loss: 2.4651\n",
            "Epoch 32/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1968 - val_loss: 2.4284\n",
            "Epoch 33/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2001 - val_loss: 2.3887\n",
            "Epoch 34/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.2137 - val_loss: 2.3525\n",
            "Epoch 35/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.7882 - val_loss: 2.3195\n",
            "Epoch 36/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.0854 - val_loss: 2.2869\n",
            "Epoch 37/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.7188 - val_loss: 2.2530\n",
            "Epoch 38/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.8943 - val_loss: 2.2177\n",
            "Epoch 39/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.1300 - val_loss: 2.1899\n",
            "Epoch 40/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.8908 - val_loss: 2.1573\n",
            "Epoch 41/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.7597 - val_loss: 2.1251\n",
            "Epoch 42/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.8472 - val_loss: 2.0911\n",
            "Epoch 43/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.7613 - val_loss: 2.0663\n",
            "Epoch 44/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.6647 - val_loss: 2.0425\n",
            "Epoch 45/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.5696 - val_loss: 2.0129\n",
            "Epoch 46/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.0052 - val_loss: 1.9879\n",
            "Epoch 47/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4453 - val_loss: 1.9600\n",
            "Epoch 48/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.5321 - val_loss: 1.9276\n",
            "Epoch 49/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.8159 - val_loss: 1.9065\n",
            "Epoch 50/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4733 - val_loss: 1.8849\n",
            "Epoch 51/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.6049 - val_loss: 1.8577\n",
            "Epoch 52/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3418 - val_loss: 1.8323\n",
            "Epoch 53/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.6098 - val_loss: 1.8150\n",
            "Epoch 54/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4895 - val_loss: 1.7944\n",
            "Epoch 55/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3385 - val_loss: 1.7674\n",
            "Epoch 56/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.6185 - val_loss: 1.7431\n",
            "Epoch 57/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4980 - val_loss: 1.7221\n",
            "Epoch 58/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1939 - val_loss: 1.7078\n",
            "Epoch 59/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3870 - val_loss: 1.6811\n",
            "Epoch 60/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2325 - val_loss: 1.6619\n",
            "Epoch 61/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4739 - val_loss: 1.6455\n",
            "Epoch 62/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3145 - val_loss: 1.6268\n",
            "Epoch 63/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2516 - val_loss: 1.6100\n",
            "Epoch 64/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.5030 - val_loss: 1.6050\n",
            "Epoch 65/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1423 - val_loss: 1.5794\n",
            "Epoch 66/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4178 - val_loss: 1.5625\n",
            "Epoch 67/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0963 - val_loss: 1.5466\n",
            "Epoch 68/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2475 - val_loss: 1.5209\n",
            "Epoch 69/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2233 - val_loss: 1.5086\n",
            "Epoch 70/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2090 - val_loss: 1.4934\n",
            "Epoch 71/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3356 - val_loss: 1.4796\n",
            "Epoch 72/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1582 - val_loss: 1.4709\n",
            "Epoch 73/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2753 - val_loss: 1.4552\n",
            "Epoch 74/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1975 - val_loss: 1.4378\n",
            "Epoch 75/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3044 - val_loss: 1.4254\n",
            "Epoch 76/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1594 - val_loss: 1.4105\n",
            "Epoch 77/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4497 - val_loss: 1.3955\n",
            "Epoch 78/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2012 - val_loss: 1.3862\n",
            "Epoch 79/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2457 - val_loss: 1.3728\n",
            "Epoch 80/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2039 - val_loss: 1.3588\n",
            "Epoch 81/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.3484 - val_loss: 1.3523\n",
            "Epoch 82/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.4838 - val_loss: 1.3382\n",
            "Epoch 83/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2674 - val_loss: 1.3319\n",
            "Epoch 84/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9997 - val_loss: 1.3149\n",
            "Epoch 85/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2759 - val_loss: 1.2997\n",
            "Epoch 86/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0664 - val_loss: 1.2874\n",
            "Epoch 87/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0835 - val_loss: 1.2737\n",
            "Epoch 88/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0722 - val_loss: 1.2633\n",
            "Epoch 89/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0923 - val_loss: 1.2529\n",
            "Epoch 90/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2269 - val_loss: 1.2453\n",
            "Epoch 91/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0427 - val_loss: 1.2369\n",
            "Epoch 92/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0276 - val_loss: 1.2234\n",
            "Epoch 93/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1195 - val_loss: 1.2215\n",
            "Epoch 94/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9612 - val_loss: 1.2049\n",
            "Epoch 95/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9541 - val_loss: 1.1989\n",
            "Epoch 96/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2241 - val_loss: 1.1887\n",
            "Epoch 97/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0634 - val_loss: 1.1825\n",
            "Epoch 98/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9399 - val_loss: 1.1720\n",
            "Epoch 99/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0947 - val_loss: 1.1644\n",
            "Epoch 100/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1076 - val_loss: 1.1626\n",
            "Epoch 101/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9908 - val_loss: 1.1484\n",
            "Epoch 102/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.2264 - val_loss: 1.1367\n",
            "Epoch 103/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1732 - val_loss: 1.1317\n",
            "Epoch 104/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0980 - val_loss: 1.1238\n",
            "Epoch 105/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9013 - val_loss: 1.1131\n",
            "Epoch 106/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9850 - val_loss: 1.1159\n",
            "Epoch 107/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0687 - val_loss: 1.1059\n",
            "Epoch 108/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9370 - val_loss: 1.0954\n",
            "Epoch 109/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9921 - val_loss: 1.0818\n",
            "Epoch 110/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0005 - val_loss: 1.0767\n",
            "Epoch 111/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0611 - val_loss: 1.0669\n",
            "Epoch 112/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9197 - val_loss: 1.0578\n",
            "Epoch 113/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0401 - val_loss: 1.0573\n",
            "Epoch 114/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1387 - val_loss: 1.0523\n",
            "Epoch 115/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0064 - val_loss: 1.0436\n",
            "Epoch 116/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9398 - val_loss: 1.0312\n",
            "Epoch 117/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8631 - val_loss: 1.0233\n",
            "Epoch 118/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9305 - val_loss: 1.0129\n",
            "Epoch 119/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1344 - val_loss: 1.0085\n",
            "Epoch 120/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.1722 - val_loss: 0.9997\n",
            "Epoch 121/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9992 - val_loss: 0.9918\n",
            "Epoch 122/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9068 - val_loss: 0.9807\n",
            "Epoch 123/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9910 - val_loss: 0.9777\n",
            "Epoch 124/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9606 - val_loss: 0.9690\n",
            "Epoch 125/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8511 - val_loss: 0.9604\n",
            "Epoch 126/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8088 - val_loss: 0.9585\n",
            "Epoch 127/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0827 - val_loss: 0.9471\n",
            "Epoch 128/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0029 - val_loss: 0.9445\n",
            "Epoch 129/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8379 - val_loss: 0.9368\n",
            "Epoch 130/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9895 - val_loss: 0.9277\n",
            "Epoch 131/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9072 - val_loss: 0.9226\n",
            "Epoch 132/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7012 - val_loss: 0.9138\n",
            "Epoch 133/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8922 - val_loss: 0.9108\n",
            "Epoch 134/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8989 - val_loss: 0.9053\n",
            "Epoch 135/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8422 - val_loss: 0.8988\n",
            "Epoch 136/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8830 - val_loss: 0.8960\n",
            "Epoch 137/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7915 - val_loss: 0.8826\n",
            "Epoch 138/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9459 - val_loss: 0.8810\n",
            "Epoch 139/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9682 - val_loss: 0.8747\n",
            "Epoch 140/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0901 - val_loss: 0.8672\n",
            "Epoch 141/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7669 - val_loss: 0.8596\n",
            "Epoch 142/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9802 - val_loss: 0.8533\n",
            "Epoch 143/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8790 - val_loss: 0.8484\n",
            "Epoch 144/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0097 - val_loss: 0.8414\n",
            "Epoch 145/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7396 - val_loss: 0.8367\n",
            "Epoch 146/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9449 - val_loss: 0.8282\n",
            "Epoch 147/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0320 - val_loss: 0.8262\n",
            "Epoch 148/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6165 - val_loss: 0.8185\n",
            "Epoch 149/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8999 - val_loss: 0.8133\n",
            "Epoch 150/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8063 - val_loss: 0.8066\n",
            "Epoch 151/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8603 - val_loss: 0.8029\n",
            "Epoch 152/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7428 - val_loss: 0.7950\n",
            "Epoch 153/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.0049 - val_loss: 0.7948\n",
            "Epoch 154/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6626 - val_loss: 0.7874\n",
            "Epoch 155/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9310 - val_loss: 0.7834\n",
            "Epoch 156/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8532 - val_loss: 0.7806\n",
            "Epoch 157/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8290 - val_loss: 0.7746\n",
            "Epoch 158/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8022 - val_loss: 0.7659\n",
            "Epoch 159/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9545 - val_loss: 0.7622\n",
            "Epoch 160/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7036 - val_loss: 0.7567\n",
            "Epoch 161/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9062 - val_loss: 0.7534\n",
            "Epoch 162/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8974 - val_loss: 0.7494\n",
            "Epoch 163/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7506 - val_loss: 0.7454\n",
            "Epoch 164/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7896 - val_loss: 0.7406\n",
            "Epoch 165/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8330 - val_loss: 0.7351\n",
            "Epoch 166/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9392 - val_loss: 0.7316\n",
            "Epoch 167/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9249 - val_loss: 0.7272\n",
            "Epoch 168/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8875 - val_loss: 0.7254\n",
            "Epoch 169/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7887 - val_loss: 0.7187\n",
            "Epoch 170/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9739 - val_loss: 0.7173\n",
            "Epoch 171/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5757 - val_loss: 0.7135\n",
            "Epoch 172/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7422 - val_loss: 0.7063\n",
            "Epoch 173/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8915 - val_loss: 0.7036\n",
            "Epoch 174/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7317 - val_loss: 0.6985\n",
            "Epoch 175/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6192 - val_loss: 0.6936\n",
            "Epoch 176/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7526 - val_loss: 0.6896\n",
            "Epoch 177/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6865 - val_loss: 0.6855\n",
            "Epoch 178/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7703 - val_loss: 0.6820\n",
            "Epoch 179/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6369 - val_loss: 0.6794\n",
            "Epoch 180/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6764 - val_loss: 0.6791\n",
            "Epoch 181/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7425 - val_loss: 0.6738\n",
            "Epoch 182/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5991 - val_loss: 0.6691\n",
            "Epoch 183/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6866 - val_loss: 0.6650\n",
            "Epoch 184/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7228 - val_loss: 0.6621\n",
            "Epoch 185/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6490 - val_loss: 0.6604\n",
            "Epoch 186/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7901 - val_loss: 0.6554\n",
            "Epoch 187/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7651 - val_loss: 0.6523\n",
            "Epoch 188/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7873 - val_loss: 0.6494\n",
            "Epoch 189/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8148 - val_loss: 0.6459\n",
            "Epoch 190/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7068 - val_loss: 0.6435\n",
            "Epoch 191/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6984 - val_loss: 0.6413\n",
            "Epoch 192/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6861 - val_loss: 0.6377\n",
            "Epoch 193/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6325 - val_loss: 0.6348\n",
            "Epoch 194/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5605 - val_loss: 0.6320\n",
            "Epoch 195/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6964 - val_loss: 0.6290\n",
            "Epoch 196/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6974 - val_loss: 0.6262\n",
            "Epoch 197/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5356 - val_loss: 0.6243\n",
            "Epoch 198/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7555 - val_loss: 0.6202\n",
            "Epoch 199/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5030 - val_loss: 0.6180\n",
            "Epoch 200/200\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6136 - val_loss: 0.6170\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "AcVDJdMWHFNV",
        "outputId": "a54ff9a7-c0df-46af-e8d1-3375938ce451"
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.plot(r.history['loss'], label='loss')\n",
        "plt.plot(r.history['val_loss'], label='val_loss')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f3b0cf77810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw0mfbDxHX5L",
        "outputId": "e7fe291d-8640-4a2b-9c9f-744e88d4677d"
      },
      "source": [
        "test_pred = model.predict(X_test)\n",
        "train_pred = model.predict(X_train)\n",
        "\n",
        "print('Test set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_test, test_pred)\n",
        "\n",
        "print('Train set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_train, train_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set evaluation:\n",
            "_____________________________________\n",
            "MAE: 0.5786404252052307\n",
            "MSE: 0.617020501715096\n",
            "RMSE: 0.7855065255713004\n",
            "R2 Square 0.695674228500569\n",
            "Train set evaluation:\n",
            "_____________________________________\n",
            "MAE: 0.5943219192326069\n",
            "MSE: 0.6619671087435062\n",
            "RMSE: 0.8136136114541755\n",
            "R2 Square 0.63615686225022\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55q7ek-0dkTm",
        "outputId": "b14ca07d-963c-493b-9d1f-387bab25b365"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 5)                 30        \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32)                192       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 512)               66048     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 77,215\n",
            "Trainable params: 77,215\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "RcyORTavHaK6",
        "outputId": "02a5e2a5-cb3d-478b-ab51-7ed76ab2a023"
      },
      "source": [
        "results_df_2 = pd.DataFrame(data=[[\"Artficial Neural Network\", *evaluate(y_test, test_pred), 0]], \n",
        "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\n",
        "results_df = results_df.append(results_df_2, ignore_index=True)\n",
        "results_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2 Square</th>\n",
              "      <th>Cross Validation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>0.747675</td>\n",
              "      <td>0.877382</td>\n",
              "      <td>0.936687</td>\n",
              "      <td>0.567259</td>\n",
              "      <td>0.509614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Robust Regression</td>\n",
              "      <td>1.047979</td>\n",
              "      <td>2.707317</td>\n",
              "      <td>1.645393</td>\n",
              "      <td>-0.335298</td>\n",
              "      <td>-0.163998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ridge Regression</td>\n",
              "      <td>0.810667</td>\n",
              "      <td>1.156877</td>\n",
              "      <td>1.075582</td>\n",
              "      <td>0.429407</td>\n",
              "      <td>0.510120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lasso Regression</td>\n",
              "      <td>0.779502</td>\n",
              "      <td>0.952091</td>\n",
              "      <td>0.975751</td>\n",
              "      <td>0.530412</td>\n",
              "      <td>0.285220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Elastic Net Regression</td>\n",
              "      <td>0.775061</td>\n",
              "      <td>0.942852</td>\n",
              "      <td>0.971006</td>\n",
              "      <td>0.534968</td>\n",
              "      <td>0.293492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Artficial Neural Network</td>\n",
              "      <td>0.578640</td>\n",
              "      <td>0.617021</td>\n",
              "      <td>0.785507</td>\n",
              "      <td>0.695674</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      Model       MAE  ...  R2 Square  Cross Validation\n",
              "0         Linear Regression  0.747675  ...   0.567259          0.509614\n",
              "1         Robust Regression  1.047979  ...  -0.335298         -0.163998\n",
              "2          Ridge Regression  0.810667  ...   0.429407          0.510120\n",
              "3          Lasso Regression  0.779502  ...   0.530412          0.285220\n",
              "4    Elastic Net Regression  0.775061  ...   0.534968          0.293492\n",
              "5  Artficial Neural Network  0.578640  ...   0.695674          0.000000\n",
              "\n",
              "[6 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEmufqT3Hk1O"
      },
      "source": [
        "# Model Compared"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "JzRvBy6YHnnn",
        "outputId": "39e60e1e-d2d4-46cd-ae5f-eef01e35c772"
      },
      "source": [
        "results_df.set_index('Model', inplace=True)\n",
        "results_df['R2 Square'].plot(kind='barh', figsize=(12, 8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3b0b29c5d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JYN65B8edgd"
      },
      "source": [
        "# Bagged Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLtIaRXWel42"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vm-5irbGem3s",
        "outputId": "a72406af-4d98-4372-b772-6e07b2ceab07"
      },
      "source": [
        "# Bagged Tree\n",
        "bt = BaggingClassifier()\n",
        "bt.fit(X_train, y_train)\n",
        "\n",
        "print('Training accuracy:', bt.score(X_train, y_train))\n",
        "print('Test accuracy:', bt.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy: 1.0\n",
            "Test accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU88nMJSevCd"
      },
      "source": [
        "# One vs One Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oZzG5QXe08H",
        "outputId": "229e3edc-f134-4fd5-a5ee-cc5d7e7859f4"
      },
      "source": [
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "log_reg = LogisticRegression()\n",
        "ovo = OneVsOneClassifier(log_reg)\n",
        "ovo.fit(X_train, y_train)\n",
        "\n",
        "print('Training accuracy:', ovo.score(X_train, y_train))\n",
        "print('Test accuracy:', ovo.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy: 0.9625\n",
            "Test accuracy: 0.975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoCIL6pskg4y",
        "outputId": "a432a9cb-fb84-41a4-d6c9-26d55af5fcc5"
      },
      "source": [
        "y_preds = ovo.predict(X)\n",
        "print(\"Root Mean Square Error is:\\n\")\n",
        "np.sqrt(mean_squared_error(y, y_preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Root Mean Square Error is:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.6792855623746665"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CI_cXuffGcV"
      },
      "source": [
        "# Random Forest Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR0xp0hrfWfd",
        "outputId": "0fe8b5e7-79fb-4308-a1e2-bf53932cac4d"
      },
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "print('Training accuracy:', rf.score(X_train, y_train))\n",
        "print('Test accuracy:', rf.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy: 1.0\n",
            "Test accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Smb9N8S0k2jb",
        "outputId": "a36a3671-6315-45b5-8cd5-e17463d4f3ff"
      },
      "source": [
        "y_preds = rf.predict(X)\n",
        "print(\"Root Mean Square Error is:\\n\")\n",
        "np.sqrt(mean_squared_error(y, y_preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Root Mean Square Error is:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.7748239349298849"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "cXyVtHibjWUR",
        "outputId": "786a7af0-da2f-4983-a1dd-47758dee86b8"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "model = RandomForestClassifier()\n",
        "# fit the model\n",
        "model.fit(X, y)\n",
        "# get importance\n",
        "importance = model.feature_importances_\n",
        "# summarize feature importance\n",
        "for i,v in enumerate(importance):\n",
        "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
        "# plot feature importance\n",
        "pyplot.bar([x for x in range(len(importance))], importance)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature: 0, Score: 0.14101\n",
            "Feature: 1, Score: 0.01152\n",
            "Feature: 2, Score: 0.24996\n",
            "Feature: 3, Score: 0.05443\n",
            "Feature: 4, Score: 0.54308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FR1hQXmQhch0"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSS8NceUhh1p",
        "outputId": "9478c172-bda8-488b-e02f-092ab3c9b127"
      },
      "source": [
        "from sklearn import model_selection\n",
        "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, y, test_size=0.30, random_state=100)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "result = model.score(X_test, Y_test)\n",
        "print(\"Accuracy: %.2f%%\" % (result*100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 88.33%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKZOpWq4k6UY",
        "outputId": "a09f74aa-2c30-4c04-c6ee-9db410e40b80"
      },
      "source": [
        "y_preds = model.predict(X)\n",
        "print(\"Root Mean Square Error is:\\n\")\n",
        "np.sqrt(mean_squared_error(y, y_preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Root Mean Square Error is:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7071067811865476"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJfawLXDg_4O"
      },
      "source": [
        "# Validating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRbRiSSqhGIO"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.model_selection import LeavePOut\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36jxMIwnh7Q4"
      },
      "source": [
        "# KFOLD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKQsMH-JhJ69",
        "outputId": "d57cd7f3-40a5-47bb-d8dc-208c9b1509c5"
      },
      "source": [
        "kfold = model_selection.KFold(n_splits=10, random_state=100)\n",
        "model_kfold = LogisticRegression()\n",
        "results_kfold = model_selection.cross_val_score(model_kfold, X, y, cv=kfold)\n",
        "print(\"Accuracy: %.2f%%\" % (results_kfold.mean()*100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 85.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "193rwGF1h9l5"
      },
      "source": [
        "# Stratified K-fold Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlE18V-Ah4yZ",
        "outputId": "5a5c5de1-24a5-428b-e99f-3f55861fcdb2"
      },
      "source": [
        "skfold = StratifiedKFold(n_splits=3, random_state=100)\n",
        "model_skfold = LogisticRegression()\n",
        "results_skfold = model_selection.cross_val_score(model_skfold, X, y, cv=skfold)\n",
        "print(\"Accuracy: %.2f%%\" % (results_skfold.mean()*100.0))\n",
        "#85%"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 85.50%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jippnhf0ifTW"
      },
      "source": [
        "# Repeated Random Test-Train Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TItObJRnieSy",
        "outputId": "6fe681fa-19f7-4ba0-a6c6-2026e1ab94ec"
      },
      "source": [
        "kfold2 = model_selection.ShuffleSplit(n_splits=10, test_size=0.30, random_state=100)\n",
        "model_shufflecv = LogisticRegression()\n",
        "results_4 = model_selection.cross_val_score(model_shufflecv, X, y, cv=kfold2)\n",
        "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results_4.mean()*100.0, results_4.std()*100.0))\n",
        "#87%"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 87.17% (4.02%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTBybSMXjk9w"
      },
      "source": [
        "# Conclusion:\n",
        "\n",
        "I've decided that overall I prefer Logistic Regression model because I feel that the scores are very close to one another and makes me feel comfortable with the accuracy of the model. Also the RMSE is 0.7 with a score of 88.33%. Many of my models have between 80-90% but overall the RMSE is much larger than the Logistic Regression RMSE. So with that being said I believe the Logistic Regression model is the best model for this dataset."
      ]
    }
  ]
}